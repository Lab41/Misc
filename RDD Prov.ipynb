{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Notebook takes a look at how to use AST to parse out the Python code elements for future use\n",
    "###The primary portion of this code (Lexer) extends the code from Hermes.  The particular file of interest may be found at https://github.com/Lab41/hermes/blob/master/src/data_prep/git_vectorize.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part of the notebook - the visualization near the end requires Python 3, but that isn't the core of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ast import Name, BinOp, Compare, Attribute, Subscript, Expr, Call, Assign, Str, Num, Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Code snippit that we are going to try to retain and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = \"\"\"import save_load as sl\n",
    "from src.utils import glove\n",
    "from src.data_prep import jester_vectorize as jestv\n",
    "jest_jokes = sqlCtx.read.json('/Users/abethke/spark-1.6.0/jester/jester_jokes.json.gz').sample(True, 0.1,41) \n",
    "jest_rates = sqlCtx.read.json('/Users/abethke/spark-1.6.0/jester/jester_ratings.json.gz').sample(True, 0.1,41)\n",
    "glove_model = glove.Glove(\"/Users/abethke/spark-1.6.0/jester/glove.6B.50d.txt\")\n",
    "support_files = {'glove_model' : glove_model}\n",
    "jest_vect = jestv.jester_vectorize(jest_rates, jest_jokes, \"ratings\", \"glove\", **support_files)\n",
    "user_info = jest_vect.get_user_vector().repartition(20)\n",
    "train_ratings, test_ratings = user_info.randomSplit([0.9,0.1], 41)\n",
    "sl.save_to_hadoop(train_ratings, '/Users/abethke/spark-1.6.0/jester/jester_uv_train_ratings.pkl')\n",
    "sl.save_to_hadoop(test_ratings, '/Users/abethke/spark-1.6.0/jester/jester_uv_test_ratings.pkl')\n",
    "content_vect = jest_vect.get_content_vector()\n",
    "sl.save_to_hadoop(content_vect, '/Users/abethke/spark-1.6.0/jester/jester_cv_glove.pkl') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###First to get a better idea of what is going on it is helpful to look at a smaller amount of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_minig = \"\"\"glove_model = glove.Glove.hi.there(\"/Users/abethke/spark-1.6.0/jester/glove.6B.50d.txt\")\"\"\"\n",
    "c_mini = \"\"\"jest_jokes = sqlCtx.read.json('/Users/abethke/spark-1.6.0/jester/jester_jokes.json.gz').sample(True, 0.1,41,34,683) \"\"\"\n",
    "c_mini_s = \"\"\"train_ratings, test_ratings = user_info.randomSplit([0.9,0.1], 41)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ast.dump is really helpful in viewing what is in the tree - along with all of the elements available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Module(body=[Assign(targets=[Name(id='glove_model', ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Attribute(value=Name(id='glove', ctx=Load()), attr='Glove', ctx=Load()), attr='hi', ctx=Load()), attr='there', ctx=Load()), args=[Str(s='/Users/abethke/spark-1.6.0/jester/glove.6B.50d.txt')], keywords=[]))])\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_mini = ast.parse(c_minig)\n",
    "ast.dump(tree_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Module(body=[Assign(targets=[Tuple(elts=[Name(id='train_ratings', ctx=Store()), Name(id='test_ratings', ctx=Store())], ctx=Store())], value=Call(func=Attribute(value=Name(id='user_info', ctx=Load()), attr='randomSplit', ctx=Load()), args=[List(elts=[Num(n=0.9), Num(n=0.1)], ctx=Load()), Num(n=41)], keywords=[]))])\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_mini_s = \"\"\"train_ratings, test_ratings = user_info.randomSplit([0.9,0.1], 41)\"\"\"\n",
    "tree_mini = ast.parse(c_mini_s)\n",
    "ast.dump(tree_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Another way to look at ast is to parse it into a json.  For this to run you first must pip install ast2json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ast import parse\n",
    "from ast2json import ast2json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ast_var = ast2json(parse(c_mini_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"body\": [\n",
      "        {\n",
      "            \"value\": {\n",
      "                \"_type\": \"Call\", \n",
      "                \"col_offset\": 29, \n",
      "                \"starargs\": null, \n",
      "                \"args\": [\n",
      "                    {\n",
      "                        \"elts\": [\n",
      "                            {\n",
      "                                \"_type\": \"Num\", \n",
      "                                \"lineno\": 1, \n",
      "                                \"col_offset\": 52, \n",
      "                                \"n\": 0.9\n",
      "                            }, \n",
      "                            {\n",
      "                                \"_type\": \"Num\", \n",
      "                                \"lineno\": 1, \n",
      "                                \"col_offset\": 56, \n",
      "                                \"n\": 0.1\n",
      "                            }\n",
      "                        ], \n",
      "                        \"_type\": \"List\", \n",
      "                        \"ctx\": {\n",
      "                            \"_type\": \"Load\"\n",
      "                        }, \n",
      "                        \"lineno\": 1, \n",
      "                        \"col_offset\": 51\n",
      "                    }, \n",
      "                    {\n",
      "                        \"_type\": \"Num\", \n",
      "                        \"lineno\": 1, \n",
      "                        \"col_offset\": 62, \n",
      "                        \"n\": 41\n",
      "                    }\n",
      "                ], \n",
      "                \"lineno\": 1, \n",
      "                \"func\": {\n",
      "                    \"_type\": \"Attribute\", \n",
      "                    \"attr\": \"randomSplit\", \n",
      "                    \"col_offset\": 29, \n",
      "                    \"ctx\": {\n",
      "                        \"_type\": \"Load\"\n",
      "                    }, \n",
      "                    \"value\": {\n",
      "                        \"_type\": \"Name\", \n",
      "                        \"ctx\": {\n",
      "                            \"_type\": \"Load\"\n",
      "                        }, \n",
      "                        \"id\": \"user_info\", \n",
      "                        \"col_offset\": 29, \n",
      "                        \"lineno\": 1\n",
      "                    }, \n",
      "                    \"lineno\": 1\n",
      "                }, \n",
      "                \"kwargs\": null, \n",
      "                \"keywords\": []\n",
      "            }, \n",
      "            \"_type\": \"Assign\", \n",
      "            \"lineno\": 1, \n",
      "            \"col_offset\": 0, \n",
      "            \"targets\": [\n",
      "                {\n",
      "                    \"elts\": [\n",
      "                        {\n",
      "                            \"_type\": \"Name\", \n",
      "                            \"ctx\": {\n",
      "                                \"_type\": \"Store\"\n",
      "                            }, \n",
      "                            \"id\": \"train_ratings\", \n",
      "                            \"col_offset\": 0, \n",
      "                            \"lineno\": 1\n",
      "                        }, \n",
      "                        {\n",
      "                            \"_type\": \"Name\", \n",
      "                            \"ctx\": {\n",
      "                                \"_type\": \"Store\"\n",
      "                            }, \n",
      "                            \"id\": \"test_ratings\", \n",
      "                            \"col_offset\": 15, \n",
      "                            \"lineno\": 1\n",
      "                        }\n",
      "                    ], \n",
      "                    \"_type\": \"Tuple\", \n",
      "                    \"ctx\": {\n",
      "                        \"_type\": \"Store\"\n",
      "                    }, \n",
      "                    \"lineno\": 1, \n",
      "                    \"col_offset\": 0\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ], \n",
      "    \"_type\": \"Module\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print json.dumps(ast_var, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a better idea of what is in the AST (we'll vizualize this later) we can write some code to parse it\n",
    "\n",
    "Lexer is the main function with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Lexer(ast.NodeVisitor):\n",
    "    \"\"\"Parse a node from a AST and return all the information we may want about it\n",
    "\n",
    "    node_type can be either \"Import\", \"From_Import\", \"Assign_targ\" or \"Call\".\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse(self, code):\n",
    "        '''Parse text into a tree and walk the result'''  \n",
    "        tree = ast.parse(code)\n",
    "        self.visit(tree)\n",
    "\n",
    "    def visit_Import(self, node):\n",
    "        \"\"\"Called for \"import library\" statements.\"\"\"\n",
    "        items = []\n",
    "        for item in node.names:\n",
    "            items.append((node.lineno, \"Import\", item.name, item.asname))\n",
    "        self.generic_visit(node)\n",
    "        return items\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        \"\"\"Called for \"from library import object\" statements.\"\"\"\n",
    "        self.generic_visit(node)\n",
    "        items = []\n",
    "        for item in node.names:\n",
    "            items.append((item.name, item.asname))\n",
    "        return [(node.lineno, \"From_Import\", node.module, items)]\n",
    "\n",
    "    def visit_With(self, node):\n",
    "        \"\"\"Handle visiting a with statement.\"\"\"\n",
    "        items = []\n",
    "        for item in node.items:\n",
    "            items.append((node.lineno, \"Import\", leftmostname(item)))\n",
    "        self.generic_visit(node)\n",
    "        return items\n",
    "    \n",
    "    def visit_Assign(self, node):\n",
    "        \"\"\"Handle visiting an assignment\"\"\"\n",
    "        targs = node.targets\n",
    "        items = []\n",
    "        for t in targs:\n",
    "            try:\n",
    "                id_=t.id\n",
    "                #print id_\n",
    "                items.append((node.lineno, \"Assign_targ\", t.id))                                                                           \n",
    "            except AttributeError:\n",
    "                pass\n",
    "            try:\n",
    "                targ_list = []\n",
    "                for elm in t.elts:\n",
    "                    targ_list.append(leftmostname(elm))\n",
    "                items.append((node.lineno, \"Assign_targ\", targ_list))\n",
    "            except AttributeError:\n",
    "                pass   \n",
    "\n",
    "            #Also handle the tuple    \n",
    "    \n",
    "        #print node.value\n",
    "        call_info = leftmostname(node.value)\n",
    "        \n",
    "        items.append((node.lineno, \"Assign_val\", call_info))\n",
    "        self.generic_visit(node)\n",
    "        \n",
    "        return items\n",
    "        \n",
    "\n",
    "    def visit_For(self, node):\n",
    "        \"\"\"Handle visiting a for statement.\"\"\"\n",
    "        targ = node.target\n",
    "        return [(node.lineno, \"For\", leftmostname(targ))]\n",
    " \n",
    "    \n",
    "    def visit_Call(self, node):\n",
    "        \"\"\"Called for function and method calls.\"\"\"\n",
    "        # Some nodes have their name in the function object\n",
    "        n_id = None\n",
    "\n",
    "        try:\n",
    "            n_id = node.func.id\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        # Others (those called as methods, or with a library name leading) have\n",
    "        # the name in the attr block\n",
    "        try:\n",
    "            n_id = node.func.value.id + '.' + node.func.attr\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        #the above really only works when you have function.something and not function.something.more.things\n",
    "        #for that reason, for the other cases we pass the node into leftmostname and the function is parsed correctly\n",
    "        if n_id ==None:\n",
    "            n_id = leftmostname(node)\n",
    "\n",
    "        args = []\n",
    "        try:\n",
    "            call_args = node.args\n",
    "            for c in call_args:\n",
    "                args.append(leftmostname(c))\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        self.generic_visit(node)\n",
    "        if n_id:\n",
    "            return [(node.lineno, \"Call\", n_id, args)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Leftmostname is useful to iterate over the objects and find the type of instance the node is\n",
    "###A full list of the node types can be found at https://greentreesnakes.readthedocs.io/en/latest/nodes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def leftmostname(node):\n",
    "    \"\"\"Attempts to find the first name in the tree.\"\"\"\n",
    "    if isinstance(node, Name):\n",
    "        n_id = node.id\n",
    "        try:\n",
    "            n_id = n_id + '.' + node.attr\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        rtn = n_id\n",
    "    elif isinstance(node, (BinOp, Compare)):\n",
    "        rtn = leftmostname(node.left)\n",
    "    elif isinstance(node, (Attribute, Subscript, Expr)):\n",
    "        rtn = leftmostname(node.value)+ \".\" +  node.attr \n",
    "    elif isinstance(node, Call):\n",
    "        rtn = leftmostname(node.func)\n",
    "    elif isinstance(node, (BinOp, Compare)):\n",
    "        rtn = leftmostname(node.left)\n",
    "    elif isinstance(node, Assign):\n",
    "        rtn = leftmostname(node.targets[0])\n",
    "    elif isinstance(node, List):\n",
    "        try:\n",
    "            elems = []\n",
    "            for e in node.elts:\n",
    "                elems.append(leftmostname(e))\n",
    "            rtn = elems\n",
    "        except:\n",
    "            rtn = None\n",
    "    elif isinstance(node, Str):\n",
    "        # handles case of \"./my executable\"\n",
    "        rtn = node.s\n",
    "    elif isinstance(node, Num):\n",
    "        rtn=node.n\n",
    "    else:\n",
    "        rtn = None\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Assign_targ', ['train_ratings', 'test_ratings']), (1, 'Assign_val', 'user_info.randomSplit')]\n",
      "[(1, 'Call', 'user_info.randomSplit', [[0.9, 0.1], 41])]\n"
     ]
    }
   ],
   "source": [
    "#Try it out with one of the sinnipts\n",
    "tree_mini = ast.parse(c_mini_s)\n",
    "for node in ast.walk(tree_mini):\n",
    "    ret = Lexer().visit(node)\n",
    "    if ret!=None:\n",
    "        print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Ok so that worked, what about the big code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = ast.parse(c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Module(body=[Import(names=[alias(name='save_load', asname='sl')]), ImportFrom(module='src.utils', names=[alias(name='glove', asname=None)], level=0), ImportFrom(module='src.data_prep', names=[alias(name='jester_vectorize', asname='jestv')], level=0), Assign(targets=[Name(id='jest_jokes', ctx=Store())], value=Call(func=Attribute(value=Call(func=Attribute(value=Attribute(value=Name(id='sqlCtx', ctx=Load()), attr='read', ctx=Load()), attr='json', ctx=Load()), args=[Str(s='/Users/abethke/spark-1.6.0/jester/jester_jokes.json.gz')], keywords=[]), attr='sample', ctx=Load()), args=[NameConstant(value=True), Num(n=0.1), Num(n=41)], keywords=[])), Assign(targets=[Name(id='jest_rates', ctx=Store())], value=Call(func=Attribute(value=Call(func=Attribute(value=Attribute(value=Name(id='sqlCtx', ctx=Load()), attr='read', ctx=Load()), attr='json', ctx=Load()), args=[Str(s='/Users/abethke/spark-1.6.0/jester/jester_ratings.json.gz')], keywords=[]), attr='sample', ctx=Load()), args=[NameConstant(value=True), Num(n=0.1), Num(n=41)], keywords=[])), Assign(targets=[Name(id='glove_model', ctx=Store())], value=Call(func=Attribute(value=Name(id='glove', ctx=Load()), attr='Glove', ctx=Load()), args=[Str(s='/Users/abethke/spark-1.6.0/jester/glove.6B.50d.txt')], keywords=[])), Assign(targets=[Name(id='support_files', ctx=Store())], value=Dict(keys=[Str(s='glove_model')], values=[Name(id='glove_model', ctx=Load())])), Assign(targets=[Name(id='jest_vect', ctx=Store())], value=Call(func=Attribute(value=Name(id='jestv', ctx=Load()), attr='jester_vectorize', ctx=Load()), args=[Name(id='jest_rates', ctx=Load()), Name(id='jest_jokes', ctx=Load()), Str(s='ratings'), Str(s='glove')], keywords=[keyword(arg=None, value=Name(id='support_files', ctx=Load()))])), Assign(targets=[Name(id='user_info', ctx=Store())], value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id='jest_vect', ctx=Load()), attr='get_user_vector', ctx=Load()), args=[], keywords=[]), attr='repartition', ctx=Load()), args=[Num(n=20)], keywords=[])), Assign(targets=[Tuple(elts=[Name(id='train_ratings', ctx=Store()), Name(id='test_ratings', ctx=Store())], ctx=Store())], value=Call(func=Attribute(value=Name(id='user_info', ctx=Load()), attr='randomSplit', ctx=Load()), args=[List(elts=[Num(n=0.9), Num(n=0.1)], ctx=Load()), Num(n=41)], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='sl', ctx=Load()), attr='save_to_hadoop', ctx=Load()), args=[Name(id='train_ratings', ctx=Load()), Str(s='/Users/abethke/spark-1.6.0/jester/jester_uv_train_ratings.pkl')], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='sl', ctx=Load()), attr='save_to_hadoop', ctx=Load()), args=[Name(id='test_ratings', ctx=Load()), Str(s='/Users/abethke/spark-1.6.0/jester/jester_uv_test_ratings.pkl')], keywords=[])), Assign(targets=[Name(id='content_vect', ctx=Store())], value=Call(func=Attribute(value=Name(id='jest_vect', ctx=Load()), attr='get_content_vector', ctx=Load()), args=[], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='sl', ctx=Load()), attr='save_to_hadoop', ctx=Load()), args=[Name(id='content_vect', ctx=Load()), Str(s='/Users/abethke/spark-1.6.0/jester/jester_cv_glove.pkl')], keywords=[]))])\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.dump(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Import', 'save_load', 'sl')]\n",
      "[(2, 'From_Import', 'src.utils', [('glove', None)])]\n",
      "[(3, 'From_Import', 'src.data_prep', [('jester_vectorize', 'jestv')])]\n",
      "[(4, 'Assign_targ', 'jest_jokes'), (4, 'Assign_val', 'sqlCtx.read.json.sample')]\n",
      "[(5, 'Assign_targ', 'jest_rates'), (5, 'Assign_val', 'sqlCtx.read.json.sample')]\n",
      "[(6, 'Assign_targ', 'glove_model'), (6, 'Assign_val', 'glove.Glove')]\n",
      "[(7, 'Assign_targ', 'support_files'), (7, 'Assign_val', None)]\n",
      "[(8, 'Assign_targ', 'jest_vect'), (8, 'Assign_val', 'jestv.jester_vectorize')]\n",
      "[(9, 'Assign_targ', 'user_info'), (9, 'Assign_val', 'jest_vect.get_user_vector.repartition')]\n",
      "[(10, 'Assign_targ', ['train_ratings', 'test_ratings']), (10, 'Assign_val', 'user_info.randomSplit')]\n",
      "[(13, 'Assign_targ', 'content_vect'), (13, 'Assign_val', 'jest_vect.get_content_vector')]\n",
      "[(4, 'Call', 'sqlCtx.read.json.sample', [None, 0.1, 41])]\n",
      "[(5, 'Call', 'sqlCtx.read.json.sample', [None, 0.1, 41])]\n",
      "[(6, 'Call', 'glove.Glove', ['/Users/abethke/spark-1.6.0/jester/glove.6B.50d.txt'])]\n",
      "[(8, 'Call', 'jestv.jester_vectorize', ['jest_rates', 'jest_jokes', 'ratings', 'glove'])]\n",
      "[(9, 'Call', 'jest_vect.get_user_vector.repartition', [20])]\n",
      "[(10, 'Call', 'user_info.randomSplit', [[0.9, 0.1], 41])]\n",
      "[(11, 'Call', 'sl.save_to_hadoop', ['train_ratings', '/Users/abethke/spark-1.6.0/jester/jester_uv_train_ratings.pkl'])]\n",
      "[(12, 'Call', 'sl.save_to_hadoop', ['test_ratings', '/Users/abethke/spark-1.6.0/jester/jester_uv_test_ratings.pkl'])]\n",
      "[(13, 'Call', 'jest_vect.get_content_vector', [])]\n",
      "[(14, 'Call', 'sl.save_to_hadoop', ['content_vect', '/Users/abethke/spark-1.6.0/jester/jester_cv_glove.pkl'])]\n",
      "[(4, 'Call', 'sqlCtx.read.json', ['/Users/abethke/spark-1.6.0/jester/jester_jokes.json.gz'])]\n",
      "[(5, 'Call', 'sqlCtx.read.json', ['/Users/abethke/spark-1.6.0/jester/jester_ratings.json.gz'])]\n",
      "[(9, 'Call', 'jest_vect.get_user_vector', [])]\n"
     ]
    }
   ],
   "source": [
    "tree = ast.parse(c) \n",
    "for node in ast.walk(tree):\n",
    "    ret = Lexer().visit(node)\n",
    "    if ret!=None:\n",
    "        print(ret)\n",
    "        ret_info.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 'Assign_targ', 'jest_jokes'),\n",
       " (4, 'Assign_val', 'sqlCtx.read.json.sample')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_info[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Nice!!! Everything we need.  Lexer or leftmostnode may need to be modified for other types of code, but we shall see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Method for finding file paths from code using Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('a', 'anna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/abethke/spark-1.6.0/jester/jester_jokes.json.gz'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.search(\"(\\.\\./[^/]+/)*.*\", '/Users/abethke/spark-1.6.0/jester/jester_jokes.json.gz')\n",
    "m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "###This portion of the code now uses the library from XXXX to visualize the ast tree\n",
    "###It (apparently) can only run on Python3.  You also must brew install graphviz in order for it to work\n",
    "###I copied it over here as I was having difficulty running it in the command line\n",
    "###The issue could have stemmed from how graphviz was initially brought in.\n",
    "\n",
    "###At the end of the day it will make a PDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "import subprocess\n",
    "import numbers\n",
    "import re\n",
    "from uuid import uuid4 as uuid\n",
    "import optparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    parsers = {\n",
    "        \"pyast\": generate_pyast,\n",
    "        \"lib2to3\": generate_lib2to3_ast,\n",
    "        \"jinja2\": generate_jinja2_ast,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_lib2to3_ast(code):\n",
    "    from lib2to3.pgen2.driver import Driver\n",
    "    from lib2to3.pgen2 import token as pgen2_token\n",
    "    from lib2to3.pygram import python_symbols, python_grammar\n",
    "    from lib2to3 import pytree\n",
    "    from io import StringIO\n",
    "\n",
    "    token_types = list(python_symbols.__dict__.items())\n",
    "    token_types += list(pgen2_token.__dict__.items())\n",
    "\n",
    "    def transform_ast(ast):\n",
    "        transformed = {\"node_type\": next(n for n, t in token_types if t == ast.type)}\n",
    "        if ast.children:\n",
    "            transformed[\"children\"] = [transform_ast(child) for child in ast.children]\n",
    "        if isinstance(ast, pytree.Leaf):\n",
    "            if ast.value != \"\":\n",
    "                transformed[\"value\"] = ast.value\n",
    "            if ast._prefix != \"\":\n",
    "                transformed[\"prefix\"] = ast._prefix\n",
    "        return transformed\n",
    "\n",
    "    driver = Driver(python_grammar, convert=pytree.convert)\n",
    "    return transform_ast(driver.parse_stream(StringIO(code)))\n",
    "\n",
    "\n",
    "def generate_pyast(code):\n",
    "    import ast\n",
    "    def transform_ast(code_ast):\n",
    "        if isinstance(code_ast, ast.AST):\n",
    "            node = {to_camelcase(k): transform_ast(getattr(code_ast, k)) for k in code_ast._fields}\n",
    "            node['node_type'] = to_camelcase(code_ast.__class__.__name__)\n",
    "            return node\n",
    "        elif isinstance(code_ast, list):\n",
    "            return [transform_ast(el) for el in code_ast]\n",
    "        else:\n",
    "            return code_ast\n",
    "\n",
    "    return transform_ast(ast.parse(code))\n",
    "\n",
    "\n",
    "def generate_jinja2_ast(code):\n",
    "    import jinja2\n",
    "\n",
    "    def transform_ast(ast):\n",
    "        if isinstance(ast, jinja2.nodes.Node):\n",
    "            transformed = {k: transform_ast(getattr(ast, k)) for k in ast.fields + ast.attributes if k != \"environment\"}\n",
    "            transformed[\"node_type\"] = ast.__class__.__name__\n",
    "            return transformed\n",
    "        elif isinstance(ast, list):\n",
    "            return [transform_ast(el) for el in ast]\n",
    "        else:\n",
    "            return ast\n",
    "\n",
    "    env = jinja2.Environment()\n",
    "    return transform_ast(env.parse(code))\n",
    "\n",
    "\n",
    "def to_camelcase(string):\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', string).lower()\n",
    "\n",
    "\n",
    "class GraphRenderer:\n",
    "    \"\"\"\n",
    "    this class is capable of rendering data structures consisting of\n",
    "    dicts and lists as a graph using graphviz\n",
    "    \"\"\"\n",
    "\n",
    "    graphattrs = {\n",
    "        'labelloc': 't',\n",
    "        'fontcolor': 'white',\n",
    "        'bgcolor': '#333333',\n",
    "        'margin': '0',\n",
    "    }\n",
    "\n",
    "    nodeattrs = {\n",
    "        'color': 'white',\n",
    "        'fontcolor': 'white',\n",
    "        'style': 'filled',\n",
    "        'fillcolor': '#006699',\n",
    "    }\n",
    "\n",
    "    edgeattrs = {\n",
    "        'color': 'white',\n",
    "        'fontcolor': 'white',\n",
    "    }\n",
    "\n",
    "    _graph = None\n",
    "    _rendered_nodes = None\n",
    "    _max_label_len = 100\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _escape_dot_label(str):\n",
    "        return str.replace(\"\\\\\", \"\\\\\\\\\").replace(\"|\", \"\\\\|\").replace(\"<\", \"\\\\<\").replace(\">\", \"\\\\>\")\n",
    "\n",
    "\n",
    "    def _shorten_string(self, string):\n",
    "        if len(string) > self._max_label_len - 3:\n",
    "            halflen = int((self._max_label_len - 3) / 2)\n",
    "            return string[:halflen] + \"...\" + string[-halflen:]\n",
    "        return string\n",
    "\n",
    "\n",
    "    def _render_node(self, node):\n",
    "        if isinstance(node, (str, numbers.Number)) or node is None:\n",
    "            node_id = uuid()\n",
    "        else:\n",
    "            node_id = id(node)\n",
    "        node_id = str(node_id)\n",
    "\n",
    "        if node_id not in self._rendered_nodes:\n",
    "            self._rendered_nodes.add(node_id)\n",
    "            if isinstance(node, dict):\n",
    "                self._render_dict(node, node_id)\n",
    "            elif isinstance(node, list):\n",
    "                self._render_list(node, node_id)\n",
    "            else:\n",
    "                self._graph.node(node_id, label=self._escape_dot_label(self._shorten_string(repr(node))))\n",
    "\n",
    "        return node_id\n",
    "\n",
    "\n",
    "    def _render_dict(self, node, node_id):\n",
    "        self._graph.node(node_id, label=node.get(\"node_type\", \"[dict]\"))\n",
    "        for key, value in node.items():\n",
    "            if key == \"node_type\":\n",
    "                continue\n",
    "            child_node_id = self._render_node(value)\n",
    "            self._graph.edge(node_id, child_node_id, label=self._escape_dot_label(key))\n",
    "\n",
    "\n",
    "    def _render_list(self, node, node_id):\n",
    "        self._graph.node(node_id, label=\"[list]\")\n",
    "        for idx, value in enumerate(node):\n",
    "            child_node_id = self._render_node(value)\n",
    "            self._graph.edge(node_id, child_node_id, label=self._escape_dot_label(str(idx)))\n",
    "\n",
    "\n",
    "    def render(self, data, *, label=None):\n",
    "        # create the graph\n",
    "        graphattrs = self.graphattrs.copy()\n",
    "        if label is not None:\n",
    "            graphattrs['label'] = self._escape_dot_label(label)\n",
    "        graph = gv.Digraph(graph_attr = graphattrs, node_attr = self.nodeattrs, edge_attr = self.edgeattrs)\n",
    "\n",
    "        # recursively draw all the nodes and edges\n",
    "        self._graph = graph\n",
    "        self._rendered_nodes = set()\n",
    "        self._render_node(data)\n",
    "        self._graph = None\n",
    "        self._rendered_nodes = None\n",
    "\n",
    "        # display the graph\n",
    "        graph.format = \"pdf\"\n",
    "        graph.view()\n",
    "        #subprocess.Popen(['xdg-open', \"test.pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_minig = \"\"\"glove_model = glove.Glove.hi.there(\"/Users/abethke/spark-1.6.0/jester/glove.6B.50d.txt\")\"\"\"\n",
    "code = c_minig\n",
    "\n",
    "generate_ast = parsers[\"pyast\"]\n",
    "code_ast = generate_ast(code)\n",
    "\n",
    "renderer = GraphRenderer()\n",
    "renderer.render(code_ast, label=\"Test Ast\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
