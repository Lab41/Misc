{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_rows(data):\n",
    "    ''' \n",
    "    Normalize feature vector to be unit length feature vector\n",
    "    '''\n",
    "    num_rows, num_feats = data.shape\n",
    "    for i in range(num_rows):\n",
    "        norm = np.sqrt(np.sum(np.square(data[i, :])))\n",
    "        data[i, :] = data[i, :] / norm\n",
    "    return data\n",
    "\n",
    "\n",
    "# Pull content from tarfiles\n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "def plot_image(fname, plotnum=None, tarfile_dir='/tar'):\n",
    "    if plotnum:\n",
    "        plt.subplot(plotnum[0], plotnum[1], plotnum[2])\n",
    "    prefix = fname[:3]\n",
    "    tarfile_name = prefix + '.tar'\n",
    "    tarfile_full_path = os.path.join(tarfile_dir, tarfile_name)\n",
    "    tfile = tarfile.open(tarfile_full_path, 'r')\n",
    "    img_file = tfile.extractfile(fname)\n",
    "    m = mpimg.imread(img_file)\n",
    "    plt.imshow(m)\n",
    "    plt.title(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store All Data in Memory\n",
    "all_data = None\n",
    "all_fnames = None\n",
    "for fname in glob.glob('hdf5/*')[:20]:\n",
    "    print 'Loading %s'%fname\n",
    "    raw_data = h5py.File(fname, 'r')\n",
    "    data = normalize_rows(np.array(raw_data['feats']).transpose())\n",
    "    if all_fnames is not None:\n",
    "        all_data = np.concatenate((all_data, data))\n",
    "        all_fnames.extend(raw_data['filenames'][()].tolist())\n",
    "    else:\n",
    "        all_data = data\n",
    "        all_fnames = raw_data['filenames'][()].tolist()\n",
    "    datas.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hdf5/183.hdf5\n",
      "Loading hdf5/530.hdf5\n",
      "Loading hdf5/989.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Add to Engine as you go\n",
    "all_data = None\n",
    "all_fnames = None\n",
    "dimension = 4096 # Tie to size\n",
    "rbp = RandomBinaryProjections('rbp', 100)\n",
    "engine = Engine(dimension, lshashes=[rbp])\n",
    "\n",
    "for fname in glob.glob('hdf5/*')[:3]:\n",
    "    print 'Loading %s'%fname\n",
    "    raw_data = h5py.File(fname, 'r')\n",
    "    data = normalize_rows(np.array(raw_data['feats']).transpose())\n",
    "    if all_fnames is not None:\n",
    "        all_fnames.extend(raw_data['filenames'][()].tolist())\n",
    "    else:\n",
    "        all_fnames = raw_data['filenames'][()].tolist()\n",
    "    \n",
    "    if all_data is None: # So we have some stuff to test with\n",
    "        all_data = data\n",
    "        \n",
    "    for i in range(data.shape[0]):\n",
    "        engine.store_vector(data[i,:], raw_data['filenames'][i])\n",
    "        total_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NearPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nearpy import Engine\n",
    "from nearpy.hashes import RandomBinaryProjections\n",
    "rbp = RandomBinaryProjections('rbp', 10)\n",
    "nearpy = Engine(dimension, lshashes=[rbp])\n",
    "for i in range(all_data.shape[0]):\n",
    "    nearpy.store_vector(all_data[i, :], all_fnames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_NEIGHBORS= 3\n",
    "import time\n",
    "for src_idx in range(200,210):\n",
    "    # Get Source Image\n",
    "    src_fname = all_fnames[src_idx]\n",
    "    plt.figure()\n",
    "    plot_image(src_fname, [2, NUM_NEIGHBORS, 2])\n",
    "    \n",
    "    # Get nearest neighbors\n",
    "    nns = [x[1] for x in nearpy.neighbours(all_data[src_idx, :])][1:NUM_NEIGHBORS+1]\n",
    "    for i, nn_fname in enumerate(nns):\n",
    "        plot_image(nn_fname, [2, NUM_NEIGHBORS, NUM_NEIGHBORS + i+1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "annoy = AnnoyIndex(dimension)\n",
    "total_count = 0\n",
    "for i in range(all_data.shape[0]):\n",
    "    annoy.add_item(total_count, all_data[i,:])\n",
    "    total_count += 1\n",
    "annoy.build(10) # 10 trees\n",
    "annoy.save('test.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_NEIGHBORS= 3\n",
    "\n",
    "for src_idx in range(0,5):\n",
    "    # Get Source Image\n",
    "    src_fname = all_fnames[src_idx]\n",
    "    plt.figure()\n",
    "    plot_image(src_fname, [2, NUM_NEIGHBORS, 2])\n",
    "    \n",
    "    # Get nearest neighbors\n",
    "    nns = annoy.get_nns_by_item(src_idx,NUM_NEIGHBORS)\n",
    "    for i, nn in enumerate(nns):\n",
    "        # Add to plot\n",
    "        nn_fname = all_fnames[int(nn)]\n",
    "        plot_image(nn_fname, [2, NUM_NEIGHBORS, NUM_NEIGHBORS + i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINHEAP Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "class MinHeap:\n",
    "    ''' A quick and dirty minheap implementation to test out the brute force search'''\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "        self.max_acceptable = None\n",
    "\n",
    "    def get_max(self):\n",
    "        return self.data[self.get_max_index()][0]\n",
    "\n",
    "    def get_max_index(self):\n",
    "        return self.data.index(max(self.data))\n",
    "\n",
    "    def insert(self, item, index):\n",
    "        if len(self.data) < self.max_size:\n",
    "            self.data.append((item, index))\n",
    "            self.max_acceptable = self.get_max()\n",
    "        elif item < self.max_acceptable:\n",
    "            del self.data[self.get_max_index()]\n",
    "            self.data.append((item, index))\n",
    "            self.max_acceptable = self.get_max()\n",
    "    def get_result(self):\n",
    "        if self.max_size == 1:\n",
    "            return self.data[0][1]\n",
    "        else:\n",
    "            return [v for (k, v) in self.data]\n",
    "\n",
    "def get_distance(v1, v2):\n",
    "    # Euclidean\n",
    "    return np.sqrt(np.sum(np.square(np.subtract(v1,v2))))\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    # Cosine Similarity (assuming normalized vectors)\n",
    "    return np.dot(v1, v2)\n",
    "\n",
    "def row_iteratble(matrix):\n",
    "    for i in range(matrix.shape[0]):\n",
    "        yield matrix[i, :]\n",
    "\n",
    "def get_min_distances_index(source, targets, skip_index, heap_size):\n",
    "    mh = MinHeap(heap_size)\n",
    "    for i in range(len(targets)):\n",
    "        if i != skip_index:\n",
    "            mh.insert(get_distance(source, targets[i, :]), i)\n",
    "    return mh.get_result()\n",
    "\n",
    "def find_nn_index(data, index, num_results):\n",
    "    source = data[index, :]\n",
    "    min_index = get_min_distances_index(source, data, index, num_results)\n",
    "    return min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_NEIGHBORS= 3\n",
    "for src_idx in range(162,170):\n",
    "    nns = find_nn_index(all_data, src_idx, NUM_NEIGHBORS)\n",
    "    #print src_idx, nn, get_distance(all_data[src_idx, :], all_data[nn, :])\n",
    "    \n",
    "    src_fname = os.path.basename(all_fnames[src_idx])\n",
    "    plt.figure()\n",
    "    plot_image(src_fname, [2, NUM_NEIGHBORS, 2])\n",
    "    for i, nn in enumerate(nns):\n",
    "        nn_fname = os.path.basename(all_fnames[nn])\n",
    "        plot_image(nn_fname, [2, NUM_NEIGHBORS, NUM_NEIGHBORS + i+1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
